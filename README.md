# Algorithms from scratch
I started following tutorials on writing machine learning algorithms from scratch in python,
as it has become too easy to just import and use packages without knowing how exactly a ML-algo
comes about its predictions. <br>
I noticed that when comparing the results of different machine learning models for Kaggle cases
or work problems, I sometimes did not understand why exactly one performed better than the other. <br>
I have combined resources from different tutorials in a way that I myself understand them,
but perhaps they might be useful to other people too. <br>

## Algorithms done and to do
Starting of simple and increasing complexity. <br>
Done: Simple Linear Regression <br>
Done: Multiple Linear Regression <br>
Done: Logistic regression <br>
Done: Decision Tree <br>
Done: Random Forest <br>
Doing: XGBoost <br>
Doing: Alternating Least Squares <br>
To do: Neural Network <br>

## Additional info
As mentioned earlier, I have gathered information from multiple websites per algo. <br>
I have tried to keep track of resources and stated them in the notebooks, but might have missed some
or have just forgotten in some cases.

## Structure
The algorithms 'explained' are numbered in order so that complexity increases and
chunks of code from one notebook can be used in another. E.g. the random forest uses the
code from the decision tree notebook. The code will be full visible and not imported.
However, the explanation for the code will only be in the first notebook. <br>
<br>
Apart from that there is some folders for datasets, which are used as examples,
and images which contain jpegs used in the notebooks.

### Notebooks not showing in guthub?
Go to: https://nbviewer.jupyter.org/
and paste in the github url to the notebook like: https://github.com/VincentPe/Algorithms_from_scratch/blob/master/03%20Multiple%20Linear%20Regression.ipynb <br>
Gives a better view of the document as well.
